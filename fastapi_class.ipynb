{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c25409",
   "metadata": {},
   "source": [
    "# Podemos usar ML con inferencia por fast api, util para dispositivos que no pueden ejecutar estos modelos o deserializar estos modelos en estos dispositivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e68fbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip -q install fastapi uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56810834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return({\"message\": \"Hello, World!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49fb15d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Item(BaseModel):\n",
    "    name: str\n",
    "    price: float\n",
    "    is_offer: bool = False\n",
    "\n",
    "@app.post(\"/items/\")\n",
    "def create_item(item: Item):\n",
    "    return {\"item_name\": item.name, \"item_price\": item.price}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5efe35",
   "metadata": {},
   "source": [
    "API para inferencia de ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13bb521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Validacion de parametros de entrada\n",
    "class IrisFeatures(BaseModel):\n",
    "    sepal_lenght: float = Field( ... , ge=0, description=\"Longitud del sepalo\")\n",
    "    sepal_width: float = Field( ... , ge=0, description=\"Ancho del sepalo\")\n",
    "    petal_lenght: float = Field( ... , ge=0, description=\"Longitud del petalo\")\n",
    "    petal_width: float = Field( ... , ge=0, description=\"Ancho del petalo\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0448948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respuesta del modelo\n",
    "class PredictResponse(BaseModel):\n",
    "    prediction: int\n",
    "    species: str\n",
    "    confidence: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe6ec152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Deserializamos el modelo, el Api y el mapeo de las predicciones a especies\n",
    "\n",
    "app = FastAPI(title=\"Iris Classification API\")\n",
    "\n",
    "model = joblib.load(\"iris_model.joblib\")\n",
    "\n",
    "species_map = {\n",
    "            0 : \"Setosa\",\n",
    "            1 : \"Versicolor\",\n",
    "            2 : \"equisde\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2c3f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/predict\", response_model=PredictResponse)\n",
    "\n",
    "def predict(features: IrisFeatures):\n",
    "    # Preparar datos para el modelo\n",
    "    X = np.array ([[features.sepal_lenght, features.sepal_width,\n",
    "                    features.petal_lenght, features.petal_width]])\n",
    "    \n",
    "    # Realizar prediccion\n",
    "    prediction = model.predict(X)[0]\n",
    "    confidence = model.predict_proba(X)[0].max()\n",
    "\n",
    "    return {\n",
    "        \"prediction\": int(prediction),\n",
    "        \"species\" : species_map[prediction],\n",
    "        \"confidence\" : float(confidence)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7166bdf3",
   "metadata": {},
   "source": [
    "Consideraciones en produccion:\n",
    "- Validacion estricta de entrada\n",
    "- Autenticacion y autorizacion para controlar acceso (para costos computacionales altos checar quien puede entrar)\n",
    "- Rate limiting para prevenir abuso (tiene que ser a nivel de usuario)\n",
    "- Manejo de errores y logging para monitoreo\n",
    "- Batch predictions para multiples muestras\n",
    "- Monitoreo de predicciones para detectar drift del modelo (El modelo cambia porque el modelo cambia o las predicciones cambian, tenemos que actualizar nuestros modelos)\n",
    "- Containeraizacion (Docker) para despliegue consistente (Usar Docker para estandarizar las dependencias de sus entornos)\n",
    "- Recoleccion de nuevos datos para re-entrenamiento continuo\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
